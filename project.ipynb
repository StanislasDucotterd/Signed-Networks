{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, pred):\n",
    "    y = (y + 1) / 2\n",
    "    pred = (pred + 1) / 2\n",
    "    \n",
    "    return 1 - np.sum(np.abs(y - pred)) / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(X_input, y_input, standardize=True):\n",
    "    \n",
    "    X = X_input.copy()\n",
    "    y = y_input.copy()\n",
    "    \n",
    "    if standardize:\n",
    "        for column in X:\n",
    "            X.loc[:,column] = (X[column] - X[column].mean()) / X[column].std()\n",
    "    \n",
    "    num_lines = len(X) // 10\n",
    "    accuracies = []\n",
    "    betas = np.zeros((len(X.columns), 1))\n",
    "    intercept = 0\n",
    "    for i in range(10):\n",
    "        X_test = X[i*num_lines:(i+1)*num_lines]\n",
    "        y_test = y[i*num_lines:(i+1)*num_lines]\n",
    "        \n",
    "        X_train = pd.concat([X[:i*num_lines], X[(i+1)*num_lines:]])\n",
    "        y_train = pd.concat([y[:i*num_lines], y[(i+1)*num_lines:]])\n",
    "        clf = sk.LogisticRegression(penalty='none', max_iter=10000).fit(X_train, y_train)\n",
    "        accuracies.append(accuracy(y_test.values, clf.predict(X_test)))\n",
    "        betas += clf.coef_.reshape(-1, 1) / 10\n",
    "        intercept += clf.intercept_\n",
    "        \n",
    "    return np.mean(accuracies), betas, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Data/'\n",
    "\n",
    "#Importing the epinions dataset\n",
    "\n",
    "epinions = pd.read_csv(PATH + 'epinions_signed.txt', sep = '\\t', header = 3)\n",
    "epinions.rename(columns={'# FromNodeId': 'source', 'ToNodeId': 'target', 'Sign': 'sign'}, inplace=True)\n",
    "\n",
    "#Importing the slashdot dataset\n",
    "\n",
    "slashdot = pd.read_csv(PATH + 'slashdot_signed.txt', sep = '\\t', header = 3)\n",
    "slashdot.rename(columns={'# FromNodeId': 'source', 'ToNodeId': 'target', 'Sign': 'sign'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The wikipedia dataset is quite old and quite chaotic, We need to parse it a little bit.\n",
    "\n",
    "with open(PATH + 'wikipedia_signed.txt', 'r', encoding='latin-1') as f:\n",
    "    lines = f.readlines()\n",
    "with open(PATH + 'wikipedia_signed2.txt', 'w', encoding='latin-1') as f:\n",
    "    for line in lines:\n",
    "        if line.strip(\"\\n\").startswith('U') or line.strip(\"\\n\").startswith('V'):\n",
    "            f.write(line)\n",
    "            \n",
    "wikipedia = pd.read_csv(PATH + 'wikipedia_signed2.txt', sep = '\\t', encoding='latin-1', header=None,\\\n",
    "                   names=['user/voter', 'sign', 'source'])\n",
    "\n",
    "wikipedia.loc[wikipedia['user/voter'] == 'U', 'source'] = wikipedia['sign']\n",
    "wikipedia['target'] = 0\n",
    "\n",
    "current_id = 0\n",
    "for i, row in wikipedia.iterrows():\n",
    "    if row[0] == 'U':\n",
    "        current_id = row[2]\n",
    "    else:\n",
    "        wikipedia.at[i,'target'] = current_id\n",
    "        \n",
    "wikipedia = wikipedia[wikipedia['user/voter'] == 'V']\n",
    "wikipedia = wikipedia[['source', 'target', 'sign']]\n",
    "wikipedia['source'] = wikipedia['source'].astype(int)\n",
    "\n",
    "#Wikipedia has edges with weight 0 when the user did not make a decision about the promotion, I remove them\n",
    "\n",
    "wikipedia = wikipedia[wikipedia['sign'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The epinions and wikipedia dataset contains some self-loops, they are of no use for this project.\n",
    "\n",
    "epinions = epinions[epinions['source'] != epinions['target']]\n",
    "slashdot = slashdot[slashdot['source'] != slashdot['target']]\n",
    "wikipedia = wikipedia[wikipedia['source'] != wikipedia['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>128552</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  sign\n",
       "0       0       1    -1\n",
       "1       1  128552    -1\n",
       "2       2       3     1\n",
       "3       4       5    -1\n",
       "4       4     155    -1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epinions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  sign\n",
       "0       0       1     1\n",
       "1       0       2     1\n",
       "2       0       3     1\n",
       "3       0       4     1\n",
       "4       0       5     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slashdot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  sign\n",
       "1       3      30     1\n",
       "2      25      30    -1\n",
       "3       4      30     1\n",
       "4       5      30     1\n",
       "5       6      30     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_epinions = nx.from_pandas_edgelist(epinions, 'source', 'target', 'sign')\n",
    "diG_epinions = nx.from_pandas_edgelist(epinions, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "G_slashdot = nx.from_pandas_edgelist(slashdot, 'source', 'target', 'sign')\n",
    "diG_slashdot = nx.from_pandas_edgelist(slashdot, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "G_wikipedia = nx.from_pandas_edgelist(wikipedia, 'source', 'target', 'sign')\n",
    "diG_wikipedia = nx.from_pandas_edgelist(wikipedia, 'source', 'target', 'sign', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of common Neighbors\n",
    "\n",
    "epinions['embeddedness'] = epinions.apply(lambda x: len(list(nx.common_neighbors(G_epinions, x['source'],\\\n",
    "                                                                                     x['target']))), axis=1)\n",
    "\n",
    "slashdot['embeddedness'] = slashdot.apply(lambda x: len(list(nx.common_neighbors(G_slashdot, x['source'],\\\n",
    "                                                                                     x['target']))), axis=1)\n",
    "\n",
    "wikipedia['embeddedness'] = wikipedia.apply(lambda x: len(list(nx.common_neighbors(G_wikipedia, x['source'],\\\n",
    "                                                                                     #x['target']))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out-degree of source\n",
    "\n",
    "epinions['out-degree'] = epinions.apply(lambda x: diG_epinions.out_degree(x['source']), axis=1)\n",
    "\n",
    "slashdot['out-degree'] = slashdot.apply(lambda x: diG_slashdot.out_degree(x['source']), axis=1)\n",
    "\n",
    "wikipedia['out-degree'] = wikipedia.apply(lambda x: diG_wikipedia.out_degree(x['source']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In-degree of target\n",
    "\n",
    "epinions['in-degree'] = epinions.apply(lambda x: diG_epinions.in_degree(x['target']), axis=1)\n",
    "\n",
    "slashdot['in-degree'] = slashdot.apply(lambda x: diG_slashdot.in_degree(x['target']), axis=1)\n",
    "\n",
    "wikipedia['in-degree'] = wikipedia.apply(lambda x: diG_wikipedia.in_degree(x['target']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive in-degree of source\n",
    "\n",
    "epinions_pos = epinions[epinions['sign'] == 1]\n",
    "diG_epinions_pos = nx.from_pandas_edgelist(epinions_pos, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "in_degrees = {}\n",
    "for i in range(max(epinions['source'].max(), epinions['target'].max())):\n",
    "    if i in list(diG_epinions_pos.nodes):\n",
    "        in_degrees[i] = diG_epinions_pos.in_degree(i)\n",
    "    else:\n",
    "        in_degrees[i] = 0\n",
    "        \n",
    "in_degrees = pd.DataFrame(pd.Series(in_degrees))\n",
    "in_degrees.rename(columns={0: 'source-in-degree-pos'}, inplace=True)\n",
    "epinions = epinions.merge(in_degrees, left_on='source', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "slashdot_pos = slashdot[slashdot['sign'] == 1]\n",
    "diG_slashdot_pos = nx.from_pandas_edgelist(slashdot_pos, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "in_degrees = {}\n",
    "for i in range(max(slashdot['source'].max(), slashdot['target'].max())):\n",
    "    if i in list(diG_slashdot_pos.nodes):\n",
    "        in_degrees[i] = diG_slashdot_pos.in_degree(i)\n",
    "    else:\n",
    "        in_degrees[i] = 0\n",
    "        \n",
    "in_degrees = pd.DataFrame(pd.Series(in_degrees))\n",
    "in_degrees.rename(columns={0: 'source-in-degree-pos'}, inplace=True)\n",
    "slashdot = slashdot.merge(in_degrees, left_on='source', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "wikipedia_pos = wikipedia[wikipedia['sign'] == 1]\n",
    "diG_wikipedia_pos = nx.from_pandas_edgelist(wikipedia_pos, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "in_degrees = {}\n",
    "for i in range(max(wikipedia['source'].max(), wikipedia['target'].max())):\n",
    "    if i in list(diG_wikipedia_pos.nodes):\n",
    "        in_degrees[i] = diG_wikipedia_pos.in_degree(i)\n",
    "    else:\n",
    "        in_degrees[i] = 0\n",
    "        \n",
    "in_degrees = pd.DataFrame(pd.Series(in_degrees))\n",
    "in_degrees.rename(columns={0: 'source-in-degree-pos'}, inplace=True)\n",
    "wikipedia = wikipedia.merge(in_degrees, left_on='source', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive out-degree of source\n",
    "\n",
    "out_degrees = {}\n",
    "for i in range(max(epinions['source'].max(), epinions['target'].max())):\n",
    "    if i in list(diG_epinions_pos.nodes):\n",
    "        out_degrees[i] = diG_epinions_pos.out_degree(i)\n",
    "    else:\n",
    "        out_degrees[i] = 0\n",
    "\n",
    "out_degrees = pd.DataFrame(pd.Series(out_degrees))\n",
    "out_degrees.rename(columns={0: 'source-out-degree-pos'}, inplace=True)\n",
    "epinions = epinions.merge(out_degrees, left_on='source', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "out_degrees = {}\n",
    "for i in range(max(slashdot['source'].max(), slashdot['target'].max())):\n",
    "    if i in list(diG_slashdot_pos.nodes):\n",
    "        out_degrees[i] = diG_slashdot_pos.out_degree(i)\n",
    "    else:\n",
    "        out_degrees[i] = 0\n",
    "\n",
    "out_degrees = pd.DataFrame(pd.Series(out_degrees))\n",
    "out_degrees.rename(columns={0: 'source-out-degree-pos'}, inplace=True)\n",
    "slashdot = slashdot.merge(out_degrees, left_on='source', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "out_degrees = {}\n",
    "for i in range(max(wikipedia['source'].max(), wikipedia['target'].max())):\n",
    "    if i in list(diG_wikipedia_pos.nodes):\n",
    "        out_degrees[i] = diG_wikipedia_pos.out_degree(i)\n",
    "    else:\n",
    "        out_degrees[i] = 0\n",
    "\n",
    "out_degrees = pd.DataFrame(pd.Series(out_degrees))\n",
    "out_degrees.rename(columns={0: 'source-out-degree-pos'}, inplace=True)\n",
    "wikipedia = wikipedia.merge(out_degrees, left_on='source', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative in-degree of target\n",
    "\n",
    "epinions_neg = epinions[epinions['sign'] == -1]\n",
    "diG_epinions_neg = nx.from_pandas_edgelist(epinions_neg, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "in_degrees = {}\n",
    "for i in range(max(epinions['source'].max(), epinions['target'].max())):\n",
    "    if i in list(diG_epinions_neg.nodes):\n",
    "        in_degrees[i] = diG_epinions_neg.in_degree(i)\n",
    "    else:\n",
    "        in_degrees[i] = 0\n",
    "        \n",
    "in_degrees = pd.DataFrame(pd.Series(in_degrees))\n",
    "in_degrees.rename(columns={0: 'target-in-degree-neg'}, inplace=True)\n",
    "epinions = epinions.merge(in_degrees, left_on='target', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "slashdot_neg = slashdot[slashdot['sign'] == -1]\n",
    "diG_slashdot_neg = nx.from_pandas_edgelist(slashdot_neg, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "in_degrees = {}\n",
    "for i in range(max(slashdot['source'].max(), slashdot['target'].max())):\n",
    "    if i in list(diG_slashdot_neg.nodes):\n",
    "        in_degrees[i] = diG_slashdot_neg.in_degree(i)\n",
    "    else:\n",
    "        in_degrees[i] = 0\n",
    "        \n",
    "in_degrees = pd.DataFrame(pd.Series(in_degrees))\n",
    "in_degrees.rename(columns={0: 'target-in-degree-neg'}, inplace=True)\n",
    "slashdot = slashdot.merge(in_degrees, left_on='target', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "wikipedia_neg = wikipedia[wikipedia['sign'] == -1]\n",
    "diG_wikipedia_neg = nx.from_pandas_edgelist(wikipedia_neg, 'source', 'target', 'sign', create_using=nx.DiGraph())\n",
    "\n",
    "in_degrees = {}\n",
    "for i in range(max(wikipedia['source'].max(), wikipedia['target'].max())):\n",
    "    if i in list(diG_wikipedia_neg.nodes):\n",
    "        in_degrees[i] = diG_wikipedia_neg.in_degree(i)\n",
    "    else:\n",
    "        in_degrees[i] = 0\n",
    "        \n",
    "in_degrees = pd.DataFrame(pd.Series(in_degrees))\n",
    "in_degrees.rename(columns={0: 'target-in-degree-neg'}, inplace=True)\n",
    "wikipedia = wikipedia.merge(in_degrees, left_on='target', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative out-degree of target\n",
    "\n",
    "out_degrees = {}\n",
    "for i in range(max(epinions['source'].max(), epinions['target'].max())):\n",
    "    if i in list(diG_epinions_neg.nodes):\n",
    "        out_degrees[i] = diG_epinions_neg.out_degree(i)\n",
    "    else:\n",
    "        out_degrees[i] = 0\n",
    "        \n",
    "out_degrees = pd.DataFrame(pd.Series(out_degrees))\n",
    "out_degrees.rename(columns={0: 'target-out-degree-neg'}, inplace=True)\n",
    "epinions = epinions.merge(out_degrees, left_on='target', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "out_degrees = {}\n",
    "for i in range(max(slashdot['source'].max(), slashdot['target'].max())):\n",
    "    if i in list(diG_slashdot_neg.nodes):\n",
    "        out_degrees[i] = diG_slashdot_neg.out_degree(i)\n",
    "    else:\n",
    "        out_degrees[i] = 0\n",
    "        \n",
    "out_degrees = pd.DataFrame(pd.Series(out_degrees))\n",
    "out_degrees.rename(columns={0: 'target-out-degree-neg'}, inplace=True)\n",
    "slashdot = slashdot.merge(out_degrees, left_on='target', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "out_degrees = {}\n",
    "for i in range(max(wikipedia['source'].max(), wikipedia['target'].max())):\n",
    "    if i in list(diG_wikipedia_neg.nodes):\n",
    "        out_degrees[i] = diG_wikipedia_neg.out_degree(i)\n",
    "    else:\n",
    "        out_degrees[i] = 0\n",
    "        \n",
    "out_degrees = pd.DataFrame(pd.Series(out_degrees))\n",
    "out_degrees.rename(columns={0: 'target-out-degree-neg'}, inplace=True)\n",
    "wikipedia = wikipedia.merge(out_degrees, left_on='target', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triad_census(G, diG, source, target):\n",
    "    \"\"\"Counts every type of triads between two given nodes\"\"\"\n",
    "    \n",
    "    paths = list(nx.all_simple_paths(G, source, target, cutoff = 2))\n",
    "    \n",
    "    weights = {1: 'p', -1: 'm'}\n",
    "    triad_counts = {}\n",
    "    \n",
    "    for char1 in 'FB':\n",
    "        for char2 in 'FB':\n",
    "            for char3 in 'pm':\n",
    "                for char4 in 'pm':\n",
    "                    triad_counts[char1 + char2 + char3 + char4] = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        if len(path) == 3:\n",
    "            if diG.has_edge(path[0], path[1]) and diG.has_edge(path[1], path[2]):\n",
    "                triad_counts['FF' + weights[diG.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                                    weights[diG.get_edge_data(path[1], path[2])['sign']]] += 1\n",
    "            if diG.has_edge(path[1], path[0]) and diG.has_edge(path[1], path[2]):\n",
    "                triad_counts['BF' + weights[diG.get_edge_data(path[1], path[0])['sign']] + \\\n",
    "                                    weights[diG.get_edge_data(path[1], path[2])['sign']]] += 1\n",
    "            if diG.has_edge(path[0], path[1]) and diG.has_edge(path[2], path[1]):\n",
    "                triad_counts['FB' + weights[diG.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                                    weights[diG.get_edge_data(path[2], path[1])['sign']]] += 1\n",
    "            if diG.has_edge(path[1], path[0]) and diG.has_edge(path[2], path[1]):\n",
    "                triad_counts['BB' + weights[diG.get_edge_data(path[1], path[0])['sign']] + \\\n",
    "                                    weights[diG.get_edge_data(path[2], path[1])['sign']]] += 1\n",
    "    return triad_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the triads\n",
    "\n",
    "epinions = epinions.join(epinions.apply(lambda x: pd.Series(triad_census(G_epinions, diG_epinions,\\\n",
    "                                                                        x['source'],x['target'])), axis=1))\n",
    "\n",
    "slashdot = slashdot.join(slashdot.apply(lambda x: pd.Series(triad_census(G_slashdot, diG_slashdot,\\\n",
    "                                                                        x['source'],x['target'])), axis=1))\n",
    "\n",
    "wikipedia = wikipedia.join(wikipedia.apply(lambda x: pd.Series(triad_census(G_wikipedia, diG_wikipedia,\\\n",
    "                                                                        x['source'],x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal Embededness of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_neg = epinions[epinions['sign'] == -1]\n",
    "num_neg = len(epinions_neg)\n",
    "epinions_pos = epinions[epinions['sign'] == 1].sample(n=num_neg)\n",
    "epinions_0 = pd.concat([epinions_pos, epinions_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "epinions_0 = epinions_0.sample(frac=1)\n",
    "\n",
    "\n",
    "slashdot_neg = slashdot[slashdot['sign'] == -1]\n",
    "num_neg = len(slashdot_neg)\n",
    "slashdot_pos = slashdot[slashdot['sign'] == 1].sample(n=num_neg)\n",
    "slashdot_0 = pd.concat([slashdot_pos, slashdot_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "slashdot_0 = slashdot_0.sample(frac=1)\n",
    "\n",
    "\n",
    "wikipedia_neg = wikipedia[wikipedia['sign'] == -1]\n",
    "num_neg = len(wikipedia_neg)\n",
    "wikipedia_pos = wikipedia[wikipedia['sign'] == 1].sample(n=num_neg)\n",
    "wikipedia_0 = pd.concat([wikipedia_pos, wikipedia_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "wikipedia_0 = wikipedia_0.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_y = epinions_0['sign']\n",
    "slashdot_y = slashdot_0['sign']\n",
    "wikipedia_y = wikipedia_0['sign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with only the degree information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_degree = epinions_0[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]\n",
    "\n",
    "slashdot_degree = slashdot_0[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]\n",
    "\n",
    "wikipedia_degree = wikipedia_0[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8396215735424922"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_degree, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954402642391042"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_degree, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8113207547169811"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_degree, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying only with the triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_triads = epinions_0.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)\n",
    "\n",
    "slashdot_triads = slashdot_0.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)\n",
    "\n",
    "wikipedia_triads = wikipedia_0.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8407576615185575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_triads, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6637637960203013"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_triads, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7880720017349815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_triads, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to use everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_all = epinions_0.drop(columns = ['source', 'target', 'sign'])\n",
    "\n",
    "slashdot_all = slashdot_0.drop(columns = ['source', 'target', 'sign'])\n",
    "\n",
    "wikipedia_all = wikipedia_0.drop(columns = ['source', 'target', 'sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8769224549203525"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_all, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8139732538467734"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_all, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264150943396226"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_all, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal embeddedness of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_neg = epinions[(epinions['sign'] == -1) & (epinions['embeddedness'] >= 10)]\n",
    "num_neg = len(epinions_neg)\n",
    "epinions_pos = epinions[(epinions['sign'] == 1) & (epinions['embeddedness'] >= 10)].sample(n=num_neg)\n",
    "epinions_10 = pd.concat([epinions_pos, epinions_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "epinions_10 = epinions_10.sample(frac=1)\n",
    "\n",
    "\n",
    "slashdot_neg = slashdot[(slashdot['sign'] == -1) & (slashdot['embeddedness'] >= 10)]\n",
    "num_neg = len(slashdot_neg)\n",
    "slashdot_pos = slashdot[(slashdot['sign'] == 1) & (slashdot['embeddedness'] >= 10)].sample(n=num_neg)\n",
    "slashdot_10 = pd.concat([slashdot_pos, slashdot_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "slashdot_10 = slashdot_10.sample(frac=1)\n",
    "\n",
    "\n",
    "wikipedia_neg = wikipedia[(wikipedia['sign'] == -1) & (wikipedia['embeddedness'] >= 10)]\n",
    "num_neg = len(wikipedia_neg)\n",
    "wikipedia_pos = wikipedia[(wikipedia['sign'] == 1) & (wikipedia['embeddedness'] >= 10)].sample(n=num_neg)\n",
    "wikipedia_10 = pd.concat([wikipedia_pos, wikipedia_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "wikipedia_10 = wikipedia_10.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_y = epinions_10['sign']\n",
    "slashdot_y = slashdot_10['sign']\n",
    "wikipedia_y = wikipedia_10['sign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with only degree information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_degree = epinions_10[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]\n",
    "\n",
    "slashdot_degree = slashdot_10[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]\n",
    "\n",
    "wikipedia_degree = wikipedia_10[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8860858257477243"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_degree, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579330422125182"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_degree, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7987227248536455"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_degree, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with only triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_triads = epinions_10.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)\n",
    "\n",
    "slashdot_triads = slashdot_10.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)\n",
    "\n",
    "wikipedia_triads = wikipedia_10.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934084669845398"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_triads, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014556040756914"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_triads, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81149547631719"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_triads, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_all = epinions_10.drop(columns = ['source', 'target', 'sign'])\n",
    "\n",
    "slashdot_all = slashdot_10.drop(columns = ['source', 'target', 'sign'])\n",
    "\n",
    "wikipedia_all = wikipedia_10.drop(columns = ['source', 'target', 'sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354862014159803"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_all, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078602620087336"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_all, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215007982969664"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_all, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal embeddedness of 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_neg = epinions[(epinions['sign'] == -1) & (epinions['embeddedness'] >= 25)]\n",
    "num_neg = len(epinions_neg)\n",
    "epinions_pos = epinions[(epinions['sign'] == 1) & (epinions['embeddedness'] >= 25)].sample(n=num_neg)\n",
    "epinions_25 = pd.concat([epinions_pos, epinions_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "epinions_25 = epinions_25.sample(frac=1)\n",
    "\n",
    "\n",
    "slashdot_neg = slashdot[(slashdot['sign'] == -1) & (slashdot['embeddedness'] >= 25)]\n",
    "num_neg = len(slashdot_neg)\n",
    "slashdot_pos = slashdot[(slashdot['sign'] == 1) & (slashdot['embeddedness'] >= 25)].sample(n=num_neg)\n",
    "slashdot_25 = pd.concat([slashdot_pos, slashdot_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "slashdot_25 = slashdot_25.sample(frac=1)\n",
    "\n",
    "\n",
    "wikipedia_neg = wikipedia[(wikipedia['sign'] == -1) & (wikipedia['embeddedness'] >= 25)]\n",
    "num_neg = len(wikipedia_neg)\n",
    "wikipedia_pos = wikipedia[(wikipedia['sign'] == 1) & (wikipedia['embeddedness'] >= 25)].sample(n=num_neg)\n",
    "wikipedia_25 = pd.concat([wikipedia_pos, wikipedia_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "wikipedia_25 = wikipedia_25.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_neg = wikipedia[(wikipedia['sign'] == -1) & (wikipedia['embeddedness'] >= 25)]\n",
    "num_neg = len(wikipedia_neg)\n",
    "wikipedia_pos = wikipedia[(wikipedia['sign'] == 1) & (wikipedia['embeddedness'] >= 25)].sample(n=num_neg)\n",
    "wikipedia_25 = pd.concat([wikipedia_pos, wikipedia_neg])\n",
    "#We shuffle all the rows so we avoid the problem of having test sets consisting of only positives or negatives\n",
    "wikipedia_25 = wikipedia_25.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_y = epinions_25['sign']\n",
    "slashdot_y = slashdot_25['sign']\n",
    "wikipedia_y = wikipedia_25['sign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with only degree information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_degree = epinions_25[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]\n",
    "\n",
    "slashdot_degree = slashdot_25[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]\n",
    "\n",
    "wikipedia_degree = wikipedia_25[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8830985915492958"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_degree, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8948529411764706"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_degree, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707610146862484"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_degree, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with only triad information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_triads = epinions_25.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)\n",
    "\n",
    "slashdot_triads = slashdot_25.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)\n",
    "\n",
    "wikipedia_triads = wikipedia_25.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361226180613091"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_triads, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352941176470588"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_triads, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7979973297730306"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_triads, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_all = epinions_25.drop(columns = ['source', 'target', 'sign'])\n",
    "\n",
    "slashdot_all = slashdot_25.drop(columns = ['source', 'target', 'sign'])\n",
    "\n",
    "wikipedia_all = wikipedia_25.drop(columns = ['source', 'target', 'sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9359016846175091"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(epinions_all, epinions_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363970588235293"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_all, slashdot_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802136181575434"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_all, wikipedia_y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Quadriads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadriad_census(G, diG, source, target):\n",
    "    \"\"\"Counts every type of triads between two given nodes\"\"\"\n",
    "    \n",
    "    paths = list(nx.all_simple_paths(G, source, target, cutoff = 3))\n",
    "    \n",
    "    weights = {1: 'p', -1: 'm'}\n",
    "    triad_counts = {}\n",
    "    \n",
    "    for char1 in 'FB':\n",
    "        for char2 in 'FB':\n",
    "            for char3 in 'FB':\n",
    "                for char4 in 'pm':\n",
    "                    for char5 in 'pm':\n",
    "                        for char6 in 'pm':\n",
    "                            triad_counts[char1 + char2 + char3 + char4 + char5 + char6] = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        if len(path) == 4:\n",
    "            if diG.has_edge(path[0], path[1]) and diG.has_edge(path[1], path[2]):\n",
    "                if diG.has_edge(path[2], path[3]):\n",
    "                    triad_counts['FFF' + weights[diG.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[1], path[2])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[3])['sign']]] += 1\n",
    "                if diG.has_edge(path[3], path[2]):\n",
    "                    triad_counts['FFB' + weights[diG.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[1], path[2])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[3], path[2])['sign']]] += 1\n",
    "                    \n",
    "                    \n",
    "            if diG.has_edge(path[1], path[0]) and diG.has_edge(path[1], path[2]):\n",
    "                if diG.has_edge(path[2], path[3]):\n",
    "                    triad_counts['BFF' + weights[diG.get_edge_data(path[1], path[0])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[1], path[2])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[3])['sign']]] += 1\n",
    "                if diG.has_edge(path[3], path[2]):\n",
    "                    triad_counts['BFB' + weights[diG.get_edge_data(path[1], path[0])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[1], path[2])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[3], path[2])['sign']]] += 1\n",
    "                    \n",
    "                    \n",
    "            if diG.has_edge(path[0], path[1]) and diG.has_edge(path[2], path[1]):\n",
    "                if diG.has_edge(path[2], path[3]):\n",
    "                    triad_counts['FBF' + weights[diG.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[3])['sign']]] += 1\n",
    "                if diG.has_edge(path[3], path[2]):\n",
    "                    triad_counts['FBB' + weights[diG.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[3], path[2])['sign']]] += 1\n",
    "                    \n",
    "                    \n",
    "            if diG.has_edge(path[1], path[0]) and diG.has_edge(path[2], path[1]):\n",
    "                if diG.has_edge(path[2], path[3]):\n",
    "                    triad_counts['BBF' + weights[diG.get_edge_data(path[1], path[0])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[3])['sign']]] += 1\n",
    "                if diG.has_edge(path[3], path[2]):\n",
    "                    triad_counts['BBB' + weights[diG.get_edge_data(path[1], path[0])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[2], path[1])['sign']] + \\\n",
    "                                         weights[diG.get_edge_data(path[3], path[2])['sign']]] += 1\n",
    "    return triad_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_25 = slashdot_25.join(slashdot_25.apply(lambda x: pd.Series(quadriad_census(G_slashdot, diG_slashdot,\\\n",
    "                                                                        x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_25 = wikipedia_25.join(wikipedia_25.apply(lambda x: pd.Series(quadriad_census(G_wikipedia, diG_wikipedia,\\\n",
    "                                                                        x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_quad = slashdot_25.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign', 'FFpp', 'FFpm', 'FFmp', 'FFmm', 'FBpp',\\\n",
    "                                         'FBpm', 'FBmp', 'FBmm', 'BFpp', 'BFpm', 'BFmp', 'BFmm', 'BBpp',\\\n",
    "                                         'BBpm', 'BBmp', 'BBmm'], axis=1)\n",
    "\n",
    "wikipedia_quad = wikipedia_25.drop(columns=['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign', 'FFpp', 'FFpm', 'FFmp', 'FFmm', 'FBpp',\\\n",
    "                                         'FBpm', 'FBmp', 'FBmm', 'BFpp', 'BFpm', 'BFmp', 'BFmm', 'BBpp',\\\n",
    "                                         'BBpm', 'BBmp', 'BBmm'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_quad_all = slashdot_25.drop(columns=['source', 'target', 'sign', 'FFpp', 'FFpm', 'FFmp', 'FFmm', 'FBpp',\\\n",
    "                                         'FBpm', 'FBmp', 'FBmm', 'BFpp', 'BFpm', 'BFmp', 'BFmm', 'BBpp',\\\n",
    "                                         'BBpm', 'BBmp', 'BBmm'])\n",
    "wikipedia_quad_all = wikipedia_25.drop(columns=['source', 'target', 'sign', 'FFpp', 'FFpm', 'FFmp', 'FFmm', 'FBpp',\\\n",
    "                                         'FBpm', 'FBmp', 'FBmm', 'BFpp', 'BFpm', 'BFmp', 'BFmm', 'BBpp',\\\n",
    "                                         'BBpm', 'BBmp', 'BBmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_y_25 = slashdot_25['sign']\n",
    "wikipedia_y_25 = wikipedia_25['sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(slashdot_quad, slashdot_y_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_betas = list(zip(np.squeeze(betas), slashdot_quad.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_betas.sort(key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-11.52769480681479, 'FBFmmm'),\n",
       " (-5.268095417389494, 'FFBmpp'),\n",
       " (-5.100020686389061, 'FBFmpp'),\n",
       " (-4.754343144668427, 'FFFppp'),\n",
       " (-2.667038335833678, 'FBBppp'),\n",
       " (-2.2471899195228904, 'FFFmpm'),\n",
       " (-1.650257442978822, 'FBBppm'),\n",
       " (-1.548162004230935, 'BBFppp'),\n",
       " (-1.244324248989964, 'BFFppm'),\n",
       " (-1.233383800052531, 'BFFmpp'),\n",
       " (-1.1664099240446437, 'BBBmmm'),\n",
       " (-0.854520780623408, 'BFFmmm'),\n",
       " (-0.80951402057718, 'FFBmmm'),\n",
       " (-0.643237710736469, 'FBFppm'),\n",
       " (-0.5669334455642563, 'BFFpmp'),\n",
       " (-0.5555912090668387, 'BFBmmm'),\n",
       " (-0.518588341302396, 'BBFmpm'),\n",
       " (-0.5084015416417441, 'BBFpmm'),\n",
       " (-0.4138019770416442, 'FFFpmp'),\n",
       " (-0.39585217743959683, 'BBBppp'),\n",
       " (-0.32913903598396826, 'BFBppm'),\n",
       " (-0.30279728695599817, 'BBBppm'),\n",
       " (-0.25483835095500346, 'BFBpmp'),\n",
       " (-0.24916592254629294, 'BFFmmp'),\n",
       " (-0.20797713202999576, 'FFBmpm'),\n",
       " (-0.2029479481749145, 'BFBmpm'),\n",
       " (-0.1676418455649119, 'FBFmmp'),\n",
       " (-0.13700753877854252, 'FBFpmp'),\n",
       " (-0.12807551903749625, 'FFFpmm'),\n",
       " (-0.11210172009647508, 'BBBmmp'),\n",
       " (-0.1047792069959238, 'FBBpmp'),\n",
       " (-0.09401885732088941, 'FFFppm'),\n",
       " (-0.09292635860735383, 'FBBpmm'),\n",
       " (-0.08823509326444766, 'BFBpmm'),\n",
       " (-0.0056051518093701526, 'BBFmpp'),\n",
       " (-0.004454857916387957, 'BBBpmp'),\n",
       " (0.0010797790129884219, 'FFFmmp'),\n",
       " (0.02682998490057089, 'BFBmmp'),\n",
       " (0.06179594535199698, 'BFBmpp'),\n",
       " (0.06210684588462413, 'BBBpmm'),\n",
       " (0.15046490791441916, 'FBBmpm'),\n",
       " (0.15096279000659252, 'FBBmmm'),\n",
       " (0.19722406680234855, 'BBBmpp'),\n",
       " (0.2672373630762678, 'FFBmmp'),\n",
       " (0.29873868782352336, 'BFFpmm'),\n",
       " (0.38552762845760175, 'BBFmmm'),\n",
       " (0.4024436336414806, 'BFBppp'),\n",
       " (0.5579856784123446, 'BBFppm'),\n",
       " (0.5855398784092294, 'BBFpmp'),\n",
       " (0.5907802229953643, 'BBFmmp'),\n",
       " (0.6896769459242273, 'BBBmpm'),\n",
       " (0.6939408141627278, 'FFBpmp'),\n",
       " (0.7667918836651455, 'FFBpmm'),\n",
       " (0.8050363277727857, 'FFFmmm'),\n",
       " (0.9062877848182771, 'FBFpmm'),\n",
       " (0.9457675181385029, 'BFFmpm'),\n",
       " (1.01144583249474, 'FBBmmp'),\n",
       " (1.5102413362860048, 'FFBppm'),\n",
       " (2.204664015733017, 'BFFppp'),\n",
       " (2.2697712439324564, 'FBFmpm'),\n",
       " (2.360252584131843, 'FFBppp'),\n",
       " (2.8127928035884544, 'FBBmpp'),\n",
       " (3.60441735818419, 'FFFmpp'),\n",
       " (6.512634431365932, 'FBFppp')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148197596795728"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_quad, wikipedia_y_25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(slashdot_quad_all, slashdot_y_25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8160213618157544"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation(wikipedia_quad_all, wikipedia_y_25)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triad_census_balance(G, source, target):\n",
    "    \n",
    "    paths = list(nx.all_simple_paths(G, source, target, cutoff = 2))\n",
    "    \n",
    "    weights = {1: 'p', -1: 'm'}\n",
    "    triad_counts = {}\n",
    "    \n",
    "    for char1 in 'pm':\n",
    "        for char2 in 'pm':\n",
    "            triad_counts[char1 + char2] = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        if len(path) == 3:\n",
    "            triad_counts[weights[G.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                         weights[G.get_edge_data(path[1], path[2])['sign']]] += 1\n",
    "    return triad_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadriad_census_balance(G, source, target):\n",
    "    \n",
    "    paths = list(nx.all_simple_paths(G, source, target, cutoff = 3))\n",
    "    \n",
    "    weights = {1: 'p', -1: 'm'}\n",
    "    quadriad_counts = {}\n",
    "    \n",
    "    for char1 in 'pm':\n",
    "        for char2 in 'pm':\n",
    "            for char3 in 'pm':\n",
    "                quadriad_counts[char1 + char2 + char3] = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        if len(path) == 4:\n",
    "            quadriad_counts[weights[G.get_edge_data(path[0], path[1])['sign']] + \\\n",
    "                         weights[G.get_edge_data(path[1], path[2])['sign']] + \\\n",
    "                         weights[G.get_edge_data(path[2], path[3])['sign']]] += 1\n",
    "    return quadriad_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_reduced = epinions_25[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign']]\n",
    "\n",
    "slashdot_reduced = slashdot_25[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign']]\n",
    "\n",
    "wikipedia_reduced = wikipedia_25[['embeddedness', 'out-degree', 'in-degree', 'source-in-degree-pos',\\\n",
    "                              'source-out-degree-pos', 'target-in-degree-neg', 'target-out-degree-neg', 'source',\\\n",
    "                                           'target', 'sign']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_reduced = epinions_reduced.join(epinions_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_balance(G_epinions,x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_reduced = slashdot_reduced.join(slashdot_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_balance(G_slashdot,x['source'], x['target'])), axis=1))\n",
    "\n",
    "wikipedia_reduced = wikipedia_reduced.join(slashdot_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_balance(G_wikipedia,x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_reduced = wikipedia_reduced.join(wikipedia_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_balance(G_wikipedia,x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_reduced = wikipedia_reduced.join(wikipedia_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(quadriad_census_balance(G_wikipedia,x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_reduced = slashdot_reduced.join(slashdot_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(quadriad_census_balance(G_slashdot,x['source'], x['target'])), axis=1))\n",
    "\n",
    "wikipedia_reduced = wikipedia_reduced.join(wikipedia_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(quadriad_census_balance(G_wikipedia,x['source'], x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_reduced_triads = epinions_reduced[['pp', 'pm', 'mp', 'mm']]\n",
    "slashdot_reduced_triads = slashdot_reduced[['pp', 'pm', 'mp', 'mm']]\n",
    "wikiepdia_reduced_triads = wikipedia_reduced[['pp', 'pm', 'mp', 'mm']]\n",
    "\n",
    "slashdot_reduced_quadriads = slashdot_reduced[['ppp', 'ppm', 'pmp', 'mpp', 'pmm', 'mpm', 'mmp', 'mmm']]\n",
    "wikipedia_reduced_quadriads = wikipedia_reduced[['ppp', 'ppm', 'pmp', 'mpp', 'pmm', 'mpm', 'mmp', 'mmm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_y_reduced = epinions_reduced['sign']\n",
    "slashdot_y_reduced = slashdot_reduced['sign']\n",
    "wikipedia_y_reduced = wikipedia_reduced['sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(epinions_reduced_triads, epinions_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.34683297])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.39943877],\n",
       "       [-1.78952175],\n",
       "       [-4.7763327 ],\n",
       "       [-0.01169819]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(slashdot_reduced_triads, slashdot_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.04516573])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.25232399],\n",
       "       [-2.19057836],\n",
       "       [-5.13172741],\n",
       "       [-0.05457162]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(wikiepdia_reduced_triads, wikipedia_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67439586])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22439761],\n",
       "       [-1.04324411],\n",
       "       [-1.08419836],\n",
       "       [-0.07007986]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(slashdot_reduced_quadriads, slashdot_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-30.57173967])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06861821],\n",
       "       [-1.05265836],\n",
       "       [ 0.07814483],\n",
       "       [-2.65696839],\n",
       "       [ 0.47711665],\n",
       "       [ 0.30796233],\n",
       "       [ 0.18640541],\n",
       "       [-5.3681705 ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(wikipedia_reduced_quadriads, wikipedia_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.43682983])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45227612],\n",
       "       [-1.26664667],\n",
       "       [-0.84612195],\n",
       "       [-1.27534776],\n",
       "       [ 0.84796681],\n",
       "       [ 1.03308246],\n",
       "       [ 0.96518773],\n",
       "       [-2.28582031]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Status model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "diG_epinions_status = nx.DiGraph()\n",
    "diG_slashdot_status = nx.DiGraph()\n",
    "diG_wikipedia_status = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in diG_epinions.edges:\n",
    "    if diG_epinions.get_edge_data(edge[0], edge[1])['sign'] == 1:\n",
    "        diG_epinions_status.add_edge(edge[0], edge[1])\n",
    "    else:\n",
    "        diG_epinions_status.add_edge(edge[1], edge[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in diG_slashdot.edges:\n",
    "    if diG_slashdot.get_edge_data(edge[0], edge[1])['sign'] == 1:\n",
    "        diG_slashdot_status.add_edge(edge[0], edge[1])\n",
    "    else:\n",
    "        diG_slashdot_status.add_edge(edge[1], edge[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in diG_wikipedia.edges:\n",
    "    if diG_wikipedia.get_edge_data(edge[0], edge[1])['sign'] == 1:\n",
    "        diG_wikipedia_status.add_edge(edge[0], edge[1])\n",
    "    else:\n",
    "        diG_wikipedia_status.add_edge(edge[1], edge[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triad_census_status(G, diG, source, target):\n",
    "    \n",
    "    paths = list(nx.all_simple_paths(G, source, target, cutoff = 2))\n",
    "    \n",
    "    triad_counts = {}\n",
    "    \n",
    "    for char1 in 'FB':\n",
    "        for char2 in 'FB':\n",
    "            triad_counts[char1 + char2] = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        if len(path) == 3:\n",
    "            if diG.has_edge(path[0], path[1]):\n",
    "                if diG.has_edge(path[1], path[2]):\n",
    "                    triad_counts['FF'] += 1\n",
    "                if diG.has_edge(path[2], path[1]):\n",
    "                    triad_counts['FB'] += 1\n",
    "            if diG.has_edge(path[1], path[0]):\n",
    "                if diG.has_edge(path[1], path[2]):\n",
    "                    triad_counts['BF'] += 1\n",
    "                if diG.has_edge(path[2], path[1]):\n",
    "                    triad_counts['BB'] += 1\n",
    "                    \n",
    "    return triad_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadriad_census_status(G, diG, source, target):\n",
    "    \n",
    "    paths = list(nx.all_simple_paths(G, source, target, cutoff = 3))\n",
    "    \n",
    "    triad_counts = {}\n",
    "    \n",
    "    for char1 in 'FB':\n",
    "        for char2 in 'FB':\n",
    "            for char3 in 'FB':\n",
    "                triad_counts[char1 + char2 + char3] = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        if len(path) == 4:\n",
    "            if diG.has_edge(path[0], path[1]):\n",
    "                if diG.has_edge(path[1], path[2]):\n",
    "                    if diG.has_edge(path[2], path[3]):\n",
    "                        triad_counts['FFF'] += 1\n",
    "                    if diG.has_edge(path[3], path[2]):\n",
    "                        triad_counts['FFB'] += 1\n",
    "                        \n",
    "                if diG.has_edge(path[2], path[1]):\n",
    "                    if diG.has_edge(path[2], path[3]):\n",
    "                        triad_counts['FBF'] += 1\n",
    "                    if diG.has_edge(path[3], path[2]):   \n",
    "                        triad_counts['FBB'] += 1\n",
    "                        \n",
    "            if diG.has_edge(path[1], path[0]):\n",
    "                if diG.has_edge(path[1], path[2]):\n",
    "                    if diG.has_edge(path[2], path[3]):\n",
    "                        triad_counts['BFF'] += 1\n",
    "                    if diG.has_edge(path[3], path[2]):\n",
    "                        triad_counts['BFB'] += 1\n",
    "                if diG.has_edge(path[2], path[1]):\n",
    "                    if diG.has_edge(path[2], path[3]):\n",
    "                        triad_counts['BBF'] += 1\n",
    "                    if diG.has_edge(path[3], path[2]):\n",
    "                        triad_counts['BBB'] += 1\n",
    "                    \n",
    "    return triad_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_reduced = epinions_reduced.join(epinions_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_status(G_epinions,diG_epinions_status,x['source'], \\\n",
    "                                                                  x['target'])), axis=1))\n",
    "\n",
    "slashdot_reduced = slashdot_reduced.join(slashdot_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_status(G_slashdot,diG_slashdot_status,x['source'], \\\n",
    "                                                                  x['target'])), axis=1))\n",
    "\n",
    "wikipedia_reduced = wikipedia_reduced.join(wikipedia_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(triad_census_status(G_wikipedia,diG_wikipedia_status,x['source'], \\\n",
    "                                                                  x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_reduced = slashdot_reduced.join(slashdot_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(quadriad_census_status(G_slashdot,diG_slashdot_status,x['source'],\\\n",
    "                                                                  x['target'])), axis=1))\n",
    "\n",
    "wikipedia_reduced = wikipedia_reduced.join(wikipedia_reduced.apply(lambda x: \\\n",
    "                                    pd.Series(quadriad_census_status(G_wikipedia,diG_wikipedia_status,x['source'],\\\n",
    "                                                                  x['target'])), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_reduced_triads_stat = epinions_reduced[['FF', 'FB', 'BF', 'BB']]\n",
    "slashdot_reduced_triads_stat = slashdot_reduced[['FF', 'FB', 'BF', 'BB']]\n",
    "wikipedia_reduced_triads_stat = wikipedia_reduced[['FF', 'FB', 'BF', 'BB']]\n",
    "\n",
    "slashdot_reduced_quadriads_stat = slashdot_reduced[['FFF', 'FFB', 'FBF', 'BFF', 'FBB', 'BFB', 'BBF', 'BBB']]\n",
    "wikipedia_reduced_quadriads_stat = wikipedia_reduced[['FFF', 'FFB', 'FBF', 'BFF', 'FBB', 'BFB', 'BBF', 'BBB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(epinions_reduced_triads_stat, epinions_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.87080113])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.62825473],\n",
       "       [ 1.82120463],\n",
       "       [-0.44302065],\n",
       "       [-2.1014204 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(slashdot_reduced_triads_stat, slashdot_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.90321853])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58240284],\n",
       "       [ 2.79108266],\n",
       "       [ 1.0467067 ],\n",
       "       [-1.77516237]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(wikipedia_reduced_triads_stat, wikipedia_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42242072])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17759964],\n",
       "       [ 0.73529805],\n",
       "       [ 0.6648401 ],\n",
       "       [-1.34679417]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(slashdot_reduced_quadriads_stat, slashdot_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.47429066])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.95196216],\n",
       "       [ 5.84998175],\n",
       "       [ 4.5395544 ],\n",
       "       [ 5.27456788],\n",
       "       [-3.46645429],\n",
       "       [-1.64647627],\n",
       "       [-4.85253849],\n",
       "       [ 0.81412854]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, betas, intercept = crossValidation(wikipedia_reduced_quadriads_stat, wikipedia_y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.20507387],\n",
       "       [ 2.29558945],\n",
       "       [ 1.86995889],\n",
       "       [ 1.1729688 ],\n",
       "       [-2.46693081],\n",
       "       [ 1.29576231],\n",
       "       [-1.16574279],\n",
       "       [-1.88395997]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86324494])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slashdot_25.to_pickle(PATH + 'slashdot_quad.pkl')\n",
    "#wikipedia_25.to_pickle(PATH + 'wikipedia_quad.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epinions.to_pickle(PATH + 'epinion.pkl')\n",
    "#slashdot.to_pickle(PATH + 'slashdot.pkl')\n",
    "#wikipedia.to_pickle(PATH + 'wikipedia.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slashdot_reduced.to_pickle(PATH + 'slashdot_quad_status.pkl')\n",
    "#wikipedia_reduced.to_pickle(PATH + 'wikipedia_quad_status.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions = pd.read_pickle(PATH + 'epinion.pkl')\n",
    "slashdot = pd.read_pickle(PATH + 'slashdot.pkl')\n",
    "wikipedia = pd.read_pickle(PATH + 'wikipedia.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "slashdot_25 = pd.read_pickle(PATH + 'slashdot_quad.pkl')\n",
    "wikipedia_25 = pd.read_pickle(PATH + 'wikipedia_quad.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
